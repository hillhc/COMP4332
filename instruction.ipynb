{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cpoRui_47pOQ"
   },
   "source": [
    "## 1. Loading data and saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1678609678007,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "56Yveell5UJM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo8Z7VVq5UJO"
   },
   "source": [
    "### A. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1678609870255,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "coz-oCwS5UJP"
   },
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'label'], folder='data'):\n",
    "    '''\n",
    "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
    "        \n",
    "        You may also specify the column names to load any columns in the .csv data file.\n",
    "        Among many, \"text\" can be used as model input, and \"label\" column is the labels (sentiment). \n",
    "    '''\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"Success\")\n",
    "        return df\n",
    "    except:\n",
    "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJnx8k_s5UJQ"
   },
   "source": [
    "Then you can extract the data by specifying the desired split and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3087,
     "status": "ok",
     "timestamp": 1678609875903,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "UEJmxylT5UJR",
    "outputId": "599a719c-2f0b-425b-a76f-26f5a2aae895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the train split\n",
      "Success\n",
      "select [id, text, label] columns from the valid split\n",
      "Success\n",
      "select [id, text] columns from the test_no_label split\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train', columns=['text', 'label'], folder='data')\n",
    "valid_df = load_data('valid', columns=['id','text', 'label'], folder='data') ### id column is added for evaluate.py\n",
    "test_df = load_data('test_no_label', columns=['id', 'text'], folder='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1678609899213,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "TuA-yimg5UJS",
    "outputId": "81bca1db-177c-4182-9d8d-a19310decbbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two Wolfgang Petersen directed films together ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For fans of the series and the movies\\r\\nthis ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love the movie. The Blu-ray was fine, but it...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You don't know what is going on until the end ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We only watched a few minutes of the movie, du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Two Wolfgang Petersen directed films together ...      5\n",
       "1  For fans of the series and the movies\\r\\nthis ...      4\n",
       "2  I love the movie. The Blu-ray was fine, but it...      3\n",
       "3  You don't know what is going on until the end ...      3\n",
       "4  We only watched a few minutes of the movie, du...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head() #### Verify the data is loaded correctly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n7lkS6sqAIT0"
   },
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "luZkHLq35UJV"
   },
   "source": [
    "### A. Text data processing recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hill6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hill6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1678610498614,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "a-KE25vc5UJV"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def lower(s):\n",
    "    \"\"\"\n",
    "    :param s: a string.\n",
    "    return a string with lower characters\n",
    "    Note that we allow the input to be nested string of a list.\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: 'text mining is to identify useful information.'\n",
    "    \"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return [lower(t) for t in s]\n",
    "    if isinstance(s, str):\n",
    "        return s.lower()\n",
    "    else:\n",
    "        raise NotImplementedError(\"unknown datatype\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of stemmed words, type: list\n",
    "    e.g.\n",
    "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     results.append(ps.stem(token))\n",
    "    # return results\n",
    "\n",
    "    return [ps.stem(token) for token in tokens]\n",
    "\n",
    "def n_gram(tokens, n=1):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    :param n: the corresponding n-gram, type: int\n",
    "    return a list of n-gram tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
    "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return tokens\n",
    "    else:\n",
    "        results = list()\n",
    "        for i in range(len(tokens)-n+1):\n",
    "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
    "            results.append(\" \".join(tokens[i:i+n]))\n",
    "        return results\n",
    "\n",
    "def filter_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of filtered tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     if token not in stopwords and not token.isnumeric():\n",
    "    #         results.append(token)\n",
    "    # return results\n",
    "\n",
    "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_onehot_vector(feats, feats_dict):\n",
    "    \"\"\"\n",
    "    :param data: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
    "    for f in feats:\n",
    "        # get the feature index, return -1 if the feature is not existed\n",
    "        f_idx = feats_dict.get(f, -1)\n",
    "        if f_idx != -1:\n",
    "            # set the corresponding element as 1\n",
    "            vector[f_idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeAOeeYC5UJW"
   },
   "source": [
    "Note that you can use the `map` function to apply your preprocessing functions into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_df)):\n",
    "    try:\n",
    "        tokenize(test_df.loc[i, 'text'])\n",
    "    except: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                     A8NQVLIE0QVT4_7949\n",
      "text    Great movie, even better dubb. Blu ray is the ...\n",
      "Name: 1155, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_df.loc[1155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6268,
     "status": "ok",
     "timestamp": 1678610507492,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "hei6VERQ5UJW",
    "outputId": "94858015-82ba-4203-e52d-2d7e68a7c8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [on, trip, past, summer, lunenberg, ,, nova, s...\n",
      "1    [excellent, !, !, most, remakes, fall, short, ...\n",
      "2    [i, started, watch, movie, lousy, movie, i, st...\n",
      "3    [well, !, i, must, terribly, jaded, ., or, i, ...\n",
      "4    [dark, grim, --, fun, movie, ., watch, perform...\n"
     ]
    }
   ],
   "source": [
    "test_df['tokens'] = test_df['text'].map(tokenize).map(filter_stopwords).map(lower)\n",
    "print(test_df['tokens'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2aF74qi5UJW"
   },
   "source": [
    "Besides `nltk`, `SpaCy` may also be useful.\n",
    "\n",
    "You can explore it at https://spacy.io/\n",
    "\n",
    "Let's install it with the following command (in terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTFX-QsE5UJX"
   },
   "source": [
    "```bash\n",
    "python -m pip install spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFBq_0Xe5UJY"
   },
   "source": [
    "For more usage of SpaCy, you can refer to its documentation at this link: https://spacy.io/usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75a7A16B5UJa"
   },
   "source": [
    "## 2. Baselines\n",
    "\n",
    "Finally, we provide two example baselines for your reference. The first baseline extracts TF-iDF features from texts and use logistic regression to generate prediction. The second baseline uses Convolutional Neural Networks (CNNs) to generate prediction from texts.\n",
    "\n",
    "\n",
    "We only consider its first 3k training samples. It is just an example, you can use the data as you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpeYkRdXAOHl"
   },
   "source": [
    "### TF-IDF + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1678610733934,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "s8XXemtF5UJa"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1678610735689,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "N5AKPx2A5UJb",
    "outputId": "99c341c9-55bc-47d8-fa0d-341d9554c63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the train split\n",
      "Success\n",
      "select [text, label] columns from the valid split\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train')[:]\n",
    "valid_df = load_data('valid')\n",
    "x_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "x_valid = valid_df['text']\n",
    "y_valid = valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1678610741896,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "NooKm1m75UJb",
    "outputId": "d4aa30ed-f95b-4ef8-dcf2-7c290c5751fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(tokenizer=<function tokenize at 0x000002807D19FEC0>)),\n",
      "                ('Truncated SVD', TruncatedSVD(n_components=500)),\n",
      "                ('lr', LogisticRegression(max_iter=1000, tol=0.005))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
    "lr = LogisticRegression(tol=5e-3,max_iter=1000)\n",
    "svd = TruncatedSVD(n_components=500)\n",
    "steps = [('tfidf', tfidf),('Truncated SVD',svd),('lr', lr)]\n",
    "pipe = Pipeline(steps)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 19070,
     "status": "ok",
     "timestamp": 1678610762673,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "Xrav6WYa5UJb",
    "outputId": "69ff5979-9e95-4129-cafc-da279576040d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anacondom\\envs\\fl\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000002807D19FEC0&gt;)),\n",
       "                (&#x27;Truncated SVD&#x27;, TruncatedSVD(n_components=500)),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(max_iter=1000, tol=0.005))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000002807D19FEC0&gt;)),\n",
       "                (&#x27;Truncated SVD&#x27;, TruncatedSVD(n_components=500)),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(max_iter=1000, tol=0.005))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function tokenize at 0x000002807D19FEC0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=500)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, tol=0.005)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(tokenizer=<function tokenize at 0x000002807D19FEC0>)),\n",
       "                ('Truncated SVD', TruncatedSVD(n_components=500)),\n",
       "                ('lr', LogisticRegression(max_iter=1000, tol=0.005))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3697,
     "status": "ok",
     "timestamp": 1678610766310,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "sjSUgqGJ5UJb",
    "outputId": "970fc723-6ff2-4086-db87-d50cb0a9b780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.54      0.56       295\n",
      "           2       0.41      0.14      0.21       198\n",
      "           3       0.47      0.58      0.52       508\n",
      "           4       0.46      0.41      0.43       523\n",
      "           5       0.58      0.68      0.63       476\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.50      0.47      0.47      2000\n",
      "weighted avg       0.50      0.51      0.50      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[160  18  66  24  27]\n",
      " [ 55  28  85  21   9]\n",
      " [ 28  19 297 117  47]\n",
      " [ 18   0 141 213 151]\n",
      " [ 15   4  41  90 326]]\n",
      "accuracy 0.512\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(x_valid)\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZMSn0Hy5UJb"
   },
   "source": [
    "### CNN\n",
    "\n",
    "The second baseline is a CNN model implemented with PyTorch.\n",
    "\n",
    "First, use the following command to install pytorch (in terminal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n2fiogb5UJc"
   },
   "source": [
    "```bash\n",
    "pip install torch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1678610803799,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "70WhNXeX5UJc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23206,
     "status": "ok",
     "timestamp": 1678610943576,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "NWEZApuy5UJc"
   },
   "outputs": [],
   "source": [
    "train_text = train_df['text'].map(tokenize).map(filter_stopwords).map(stem)\n",
    "valid_text = valid_df['text'].map(tokenize).map(filter_stopwords).map(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1678610943578,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "nWvH-WcZ5UJc"
   },
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "for tokens in train_text:\n",
    "    for t in tokens:\n",
    "        if not t in word2id:\n",
    "            word2id[t] = len(word2id)\n",
    "word2id['<pad>'] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1678610943579,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "020Rz3xi5UJc"
   },
   "outputs": [],
   "source": [
    "def texts_to_id_seq(texts, padding_length=50):\n",
    "    records = []\n",
    "    for tokens in texts:\n",
    "        record = []\n",
    "        for t in tokens:\n",
    "            record.append(word2id.get(t, len(word2id)))\n",
    "        if len(record) >= padding_length:\n",
    "            records.append(record[:padding_length])\n",
    "        else:\n",
    "            records.append(record + [word2id['<pad>']] * (padding_length - len(record)))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1678610943580,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "0lT2tV3g5UJc"
   },
   "outputs": [],
   "source": [
    "train_seqs = texts_to_id_seq(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1678610944024,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "sHB6Ud3v5UJd"
   },
   "outputs": [],
   "source": [
    "valid_seqs = texts_to_id_seq(valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1678610944026,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "aubFZ3Mg5UJd"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq, y):\n",
    "        assert len(seq) == len(y)\n",
    "        self.seq = seq\n",
    "        self.y = y-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.seq[idx]), self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1678610944030,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "P1UXP-p15UJd"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(MyDataset(train_seqs, y_train), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(MyDataset(valid_seqs, y_valid), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1678610944031,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "jPCHEnSB5UJd"
   },
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(word2id)+1, embedding_dim=64)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.linear = nn.Linear(64, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.cnn(x)\n",
    "        x = torch.max(x, dim=-1)[0]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1678610944033,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "niiGxZzO5UJd"
   },
   "outputs": [],
   "source": [
    "model = mlp()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304128,
     "status": "ok",
     "timestamp": 1678611248121,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "nZHul4x_5UJe",
    "outputId": "6be5adf2-a97a-44a6-9fc1-8cb10fafe5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 123.20it/s, loss=0.0982, acc=0.281]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 529.53it/s]\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.01      0.01       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.33      0.25      0.28       508\n",
      "           3       0.28      0.02      0.04       523\n",
      "           4       0.26      0.87      0.40       476\n",
      "\n",
      "    accuracy                           0.28      2000\n",
      "   macro avg       0.20      0.23      0.15      2000\n",
      "weighted avg       0.24      0.28      0.18      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  2   0  67   7 219]\n",
      " [  1   0  50   0 147]\n",
      " [  5   0 126  16 361]\n",
      " [  3   0  87  10 423]\n",
      " [  6   0  55   3 412]]\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 141.25it/s, loss=0.0894, acc=0.392]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 534.70it/s]\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.15      0.21       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.31      0.35      0.33       508\n",
      "           3       0.30      0.56      0.39       523\n",
      "           4       0.47      0.33      0.39       476\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.29      0.28      0.26      2000\n",
      "weighted avg       0.32      0.34      0.31      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 45   0 116 104  30]\n",
      " [ 15   0  89  75  19]\n",
      " [ 30   0 177 263  38]\n",
      " [ 22   0 120 294  87]\n",
      " [ 14   0  76 230 156]]\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 138.02it/s, loss=0.0781, acc=0.495]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 532.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.15      0.22       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.29      0.79      0.42       508\n",
      "           3       0.34      0.15      0.21       523\n",
      "           4       0.57      0.31      0.40       476\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.32      0.28      0.25      2000\n",
      "weighted avg       0.36      0.34      0.29      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 45   0 227  14   9]\n",
      " [ 15   0 169   9   5]\n",
      " [ 19   0 402  63  24]\n",
      " [ 13   0 355  80  75]\n",
      " [ 22   1 233  71 149]]\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 137.92it/s, loss=0.0649, acc=0.595]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 534.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       295\n",
      "           1       0.23      0.12      0.15       198\n",
      "           2       0.33      0.32      0.33       508\n",
      "           3       0.29      0.19      0.23       523\n",
      "           4       0.42      0.51      0.46       476\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.31      0.32      0.30      2000\n",
      "weighted avg       0.32      0.33      0.32      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[134  26  73  27  35]\n",
      " [ 70  23  57  21  27]\n",
      " [122  32 165  97  92]\n",
      " [ 91  14 133  99 186]\n",
      " [ 60   5  72  94 245]]\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 141.22it/s, loss=0.0493, acc=0.718]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 535.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.34      0.33       295\n",
      "           1       0.21      0.26      0.23       198\n",
      "           2       0.33      0.31      0.32       508\n",
      "           3       0.34      0.39      0.36       523\n",
      "           4       0.50      0.38      0.43       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.34      0.34      0.33      2000\n",
      "weighted avg       0.36      0.35      0.35      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[100  58  62  51  24]\n",
      " [ 44  52  62  27  13]\n",
      " [ 79  72 158 157  42]\n",
      " [ 53  48 116 202 104]\n",
      " [ 42  17  76 160 181]]\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 132.51it/s, loss=0.0345, acc=0.818]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 537.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.32      0.32       295\n",
      "           1       0.30      0.09      0.13       198\n",
      "           2       0.32      0.54      0.40       508\n",
      "           3       0.31      0.11      0.17       523\n",
      "           4       0.42      0.52      0.47       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.33      0.32      0.30      2000\n",
      "weighted avg       0.34      0.35      0.32      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 95  16 130  10  44]\n",
      " [ 44  17 102   6  29]\n",
      " [ 71  13 276  56  92]\n",
      " [ 49   7 236  60 171]\n",
      " [ 38   3 127  61 247]]\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 141.04it/s, loss=0.0227, acc=0.894]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 534.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.35      0.33       295\n",
      "           1       0.20      0.07      0.10       198\n",
      "           2       0.32      0.49      0.39       508\n",
      "           3       0.32      0.20      0.25       523\n",
      "           4       0.45      0.47      0.46       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.32      0.32      0.31      2000\n",
      "weighted avg       0.34      0.35      0.33      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[103  20 115  23  34]\n",
      " [ 53  14  92  14  25]\n",
      " [ 75  23 250  84  76]\n",
      " [ 59  10 208 107 139]\n",
      " [ 39   4 109 102 222]]\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 144.16it/s, loss=0.0131, acc=0.954]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 531.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.32      0.32       295\n",
      "           1       0.26      0.11      0.16       198\n",
      "           2       0.33      0.39      0.36       508\n",
      "           3       0.33      0.44      0.38       523\n",
      "           4       0.52      0.35      0.42       476\n",
      "\n",
      "    accuracy                           0.36      2000\n",
      "   macro avg       0.35      0.32      0.33      2000\n",
      "weighted avg       0.37      0.36      0.35      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 93  24  96  61  21]\n",
      " [ 45  22  76  40  15]\n",
      " [ 65  21 200 184  38]\n",
      " [ 47  12 150 230  84]\n",
      " [ 33   5  85 185 168]]\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 135.59it/s, loss=0.0089, acc=0.967]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 538.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.28      0.31       295\n",
      "           1       0.21      0.18      0.20       198\n",
      "           2       0.31      0.56      0.40       508\n",
      "           3       0.34      0.27      0.30       523\n",
      "           4       0.59      0.30      0.40       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.36      0.32      0.32      2000\n",
      "weighted avg       0.38      0.35      0.34      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 83  40 137  22  13]\n",
      " [ 31  36 109  15   7]\n",
      " [ 54  50 287  98  19]\n",
      " [ 39  32 247 143  62]\n",
      " [ 38  13 142 138 145]]\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 188/188 [00:01<00:00, 139.29it/s, loss=0.00522, acc=0.987]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 536.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.46      0.34       295\n",
      "           1       0.23      0.18      0.20       198\n",
      "           2       0.32      0.24      0.28       508\n",
      "           3       0.32      0.34      0.33       523\n",
      "           4       0.46      0.39      0.42       476\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.32      0.32      0.31      2000\n",
      "weighted avg       0.34      0.33      0.33      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[135  37  54  42  27]\n",
      " [ 72  36  45  28  17]\n",
      " [131  49 123 149  56]\n",
      " [ 97  29 100 177 120]\n",
      " [ 68   9  60 152 187]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, 11):    \n",
    "    print('epoch', e)\n",
    "    model.train()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with tqdm.tqdm(train_loader) as t:\n",
    "        for x, y in t:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({'loss': total_loss/total_count, 'acc': total_acc/total_count})\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with tqdm.tqdm(valid_loader) as t:\n",
    "        for x, y in t:\n",
    "            logits = model(x)\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += len(y)\n",
    "            y_pred += logits.argmax(1).tolist()\n",
    "            y_true += y.tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2bb-SbT5UJe"
   },
   "source": [
    "Deep learning are full of tricks. \n",
    "\n",
    "In the second example above, the CNN baseline is even not good enough to beat the TFIDF+Logistic regression baseline.\n",
    "\n",
    "You can use all the techniques introduced in the lectures and tutorials to enhance your methods.\n",
    "\n",
    "Of course, you can try any other ideas to make your model distinguished.\n",
    "\n",
    "Also, if you want to use pre-trained models. here are some reference content:\n",
    "1. https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "2. https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
